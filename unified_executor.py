#!/usr/bin/env python3
"""
=============================================================================
UNIFIED EXECUTION SCRIPT - Auto-generated by Workflow Analyzer
=============================================================================
Ce script exÃ©cute tous les scripts du projet dans l'ordre optimal.
GÃ©nÃ©rÃ© le: 2026-02-04 20:10:09
=============================================================================
"""

import os
import sys
import subprocess
import time
import signal
from pathlib import Path
from enum import Enum, auto
from dataclasses import dataclass
from typing import Optional, List, Callable
import logging

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)-8s | %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('unified_execution.log')
    ]
)
log = logging.getLogger(__name__)

# =============================================================================
# FSM STATES
# =============================================================================

class State(Enum):
    START = auto()
    WORKFLOW_ANALYZER_PY = auto()
    UNIFIED_EXECUTOR_PY = auto()
    SETUP_SH = auto()
    KO_PY = auto()
    SETUP_VENV_SH = auto()
    00_CHECK_APT_SOURCES_SH = auto()
    05_INSTALL_DOCKER_SH = auto()
    01_UPDATE_UPGRADE_SH = auto()
    06_INSTALL_SURICATA_SH = auto()
    07_INSTALL_PIGPIO_SH = auto()
    09_CONFIGURE_NETWORK_SH = auto()
    PROJECT_MANAGER_PY = auto()
    W_PY = auto()
    KL_PY = auto()
    HH_PY = auto()
    EXECUTION_FLOW_PY = auto()
    AS_PY = auto()
    INTELLIGENT_ANALYZER_PY = auto()
    H_PY = auto()
    GENERATE_GRAPH_PY = auto()
    YU_PY = auto()
    I_PY = auto()
    AA_PY = auto()
    SUCCESS = auto()
    ERROR = auto()

# =============================================================================
# CONFIGURATION
# =============================================================================

@dataclass
class StepConfig:
    name: str
    script: str
    state: State
    description: str
    timeout: int = 300
    can_fail: bool = True
    on_failure: str = "abort"  # abort, skip, retry
    max_retries: int = 3
    inputs: List[str] = None
    outputs: List[str] = None

EXECUTION_STEPS: List[StepConfig] = [
    StepConfig(
        name="workflow_analyzer.py",
        script="workflow_analyzer.py",
        state=State.WORKFLOW_ANALYZER_PY,
        description="A comprehensive workflow analyzer that examines project files, detects bugs, generates finite state ",
        timeout=1800,
        can_fail=True,
        on_failure="abort",
        inputs=['ANTHROPIC_API_KEY environment variable or hardcoded key', 'Source code files in /home/tor/Downloads/ids2', 'Project directory structure'],
        outputs=['workflow_analysis.html - Interactive visualization', 'workflow_analysis_cache.json - Analysis cache', 'Console output with progress and results']
    ),
    StepConfig(
        name="unified_executor.py",
        script="unified_executor.py",
        state=State.UNIFIED_EXECUTOR_PY,
        description="Auto-generated unified execution orchestrator that runs all project scripts in optimal order with FS",
        timeout=300,
        can_fail=True,
        on_failure="abort",
        inputs=['project_dir', 'EXECUTION_STEPS configuration', 'PYTHONPATH environment'],
        outputs=['unified_execution.log', 'execution_log data', 'system state changes']
    ),
    StepConfig(
        name="setup.sh",
        script="setup.sh",
        state=State.SETUP_SH,
        description="Remote deployment script that packages and installs an IDS (Intrusion Detection System) dashboard on",
        timeout=300,
        can_fail=True,
        on_failure="abort",
        inputs=['PI_HOST (IP address)', 'PI_USER (SSH username)', 'PI_PASS (SSH password)'],
        outputs=['ids-dashboard.tar.gz archive', 'Remote directory structure on Pi', 'Installed services on Pi']
    ),
    StepConfig(
        name="ko.py",
        script="ko.py",
        state=State.KO_PY,
        description="Analyzes script dependencies using graph theory and executes them in topological order. Scans projec",
        timeout=300,
        can_fail=True,
        on_failure="abort",
        inputs=['PROJECT_DIR filesystem', '*.py, *.sh, *.bash files', 'PYTHONPATH environment variable'],
        outputs=['execution results', 'modified PYTHONPATH', 'stdout/stderr from executed scripts']
    ),
    StepConfig(
        name="setup_venv.sh",
        script="setup_venv.sh",
        state=State.SETUP_VENV_SH,
        description="Sets up a Python virtual environment named 'venv', installs dependencies from requirements.txt if pr",
        timeout=300,
        can_fail=True,
        on_failure="abort",
        inputs=['requirements.txt (optional)', '.gitignore file', 'python3 binary'],
        outputs=['venv/ directory with virtual environment', 'installed Python packages', 'updated .gitignore file']
    ),
    StepConfig(
        name="00-check-apt-sources.sh",
        script="00-check-apt-sources.sh",
        state=State.00_CHECK_APT_SOURCES_SH,
        description="Validates that APT package manager sources are properly configured by checking for existence of sour",
        timeout=5,
        can_fail=True,
        on_failure="abort",
        inputs=['/etc/apt/sources.list', '/etc/apt/sources.list.d/', 'APT configuration files'],
        outputs=['console messages in French', 'exit status (0=success, 1=failure)']
    ),
    StepConfig(
        name="05-install-docker.sh",
        script="05-install-docker.sh",
        state=State.05_INSTALL_DOCKER_SH,
        description="Installs Docker Engine via apt with GPG key verification and adds user to docker group. Enables Dock",
        timeout=300,
        can_fail=True,
        on_failure="abort",
        inputs=['INSTALL_USER env var', 'SUDO_USER env var', 'USER env var'],
        outputs=['docker service enabled', 'docker group membership', 'Docker Engine installed']
    ),
    StepConfig(
        name="01-update-upgrade.sh",
        script="01-update-upgrade.sh",
        state=State.01_UPDATE_UPGRADE_SH,
        description="Updates APT package lists and upgrades all installed Debian/Ubuntu packages to their latest versions",
        timeout=1800,
        can_fail=True,
        on_failure="abort",
        inputs=['root/sudo privileges', 'internet connection', 'APT package manager'],
        outputs=['updated package lists in /var/lib/apt/lists/', 'upgraded system packages', 'updated package cache']
    ),
    StepConfig(
        name="06-install-suricata.sh",
        script="06-install-suricata.sh",
        state=State.06_INSTALL_SURICATA_SH,
        description="Installs Suricata network intrusion detection system and updates its rule sets on Debian/Ubuntu syst",
        timeout=300,
        can_fail=True,
        on_failure="abort",
        inputs=['root privileges', 'internet connectivity', 'apt package manager'],
        outputs=['suricata binary installed', 'suricata-update tool', 'updated threat detection rules']
    ),
    StepConfig(
        name="07-install-pigpio.sh",
        script="07-install-pigpio.sh",
        state=State.07_INSTALL_PIGPIO_SH,
        description="Downloads, compiles, and installs the pigpio library from source code, then sets up and starts the p",
        timeout=300,
        can_fail=True,
        on_failure="abort",
        inputs=['PIGPIO_ARCHIVE_URL environment variable', 'internet connection', 'root privileges'],
        outputs=['pigpio library binaries', 'pigpiod daemon binary', 'systemd service file']
    ),
    StepConfig(
        name="09-configure-network.sh",
        script="09-configure-network.sh",
        state=State.09_CONFIGURE_NETWORK_SH,
        description="Configures network interface for traffic mirroring by disabling all interfaces except the designated",
        timeout=30,
        can_fail=True,
        on_failure="abort",
        inputs=['MIRROR_INTERFACE environment variable (defaults to eth0)', 'system network interfaces', 'root privileges'],
        outputs=['disabled non-mirror network interfaces', 'promiscuous mode enabled on mirror interface', 'system ready for network monitoring']
    ),
    StepConfig(
        name="project_manager.py",
        script="project_manager.py",
        state=State.PROJECT_MANAGER_PY,
        description="Unified project management script that detects Python dependencies, verifies system software, execut",
        timeout=300,
        can_fail=True,
        on_failure="abort",
        inputs=['project files (*.py, *.sh)', 'system commands', 'environment variables'],
        outputs=['requirements.txt', 'dependency reports', 'HTML interactive graph']
    ),
    StepConfig(
        name="w.py",
        script="w.py",
        state=State.W_PY,
        description="Analyzes dependencies between project scripts and executes them in topological order based on their ",
        timeout=300,
        can_fail=True,
        on_failure="abort",
        inputs=['project directory with .py/.sh/.bash files', 'networkx library', 'python3 and bash interpreters'],
        outputs=['execution logs', 'success/failure status', 'topological execution order']
    ),
    StepConfig(
        name="kl.py",
        script="kl.py",
        state=State.KL_PY,
        description="Analyzes Python source files to identify external dependencies and suggests content for requirements",
        timeout=30,
        can_fail=True,
        on_failure="continue with partial results",
        inputs=['Python source files in project directory', 'PROJECT_DIR path', 'file system access'],
        outputs=['List of external dependencies', 'requirements.txt suggestions', 'Console output with analysis results']
    ),
    StepConfig(
        name="hh.py",
        script="hh.py",
        state=State.HH_PY,
        description="This script analyzes Python source code in a project to identify external dependencies and suggests ",
        timeout=30,
        can_fail=True,
        on_failure="skip",
        inputs=['Python source files in current directory tree', 'PROJECT_DIR path', 'File system access'],
        outputs=['Console output listing external dependencies', 'Requirements.txt suggestions']
    ),
    StepConfig(
        name="execution_flow.py",
        script="execution_flow.py",
        state=State.EXECUTION_FLOW_PY,
        description="An intelligent execution flow analyzer that uses AI (Claude) to analyze Python/shell scripts, determ",
        timeout=300,
        can_fail=True,
        on_failure="abort",
        inputs=['ANTHROPIC_API_KEY environment variable', 'target directory path (/home/tor/Downloads/ids2)', 'Python/shell/YAML files in target directory'],
        outputs=['execution_flow.html interactive graph', 'execution_flow_cache.json cache file', 'console analysis reports']
    ),
    StepConfig(
        name="as.py",
        script="as.py",
        state=State.AS_PY,
        description="An intelligent file dependency analyzer that uses Claude AI to scan project files and create an inte",
        timeout=300,
        can_fail=True,
        on_failure="skip",
        inputs=['/home/tor/Downloads/ids2 directory', 'ANTHROPIC_KEY environment/hardcoded', 'analysis_cache.json'],
        outputs=['analysis_cache.json', 'dependency_map_ai.html', 'console output']
    ),
    StepConfig(
        name="intelligent_analyzer.py",
        script="intelligent_analyzer.py",
        state=State.INTELLIGENT_ANALYZER_PY,
        description="An intelligent dependency analyzer that scans Python projects, analyzes file dependencies using AI, ",
        timeout=300,
        can_fail=True,
        on_failure="abort",
        inputs=['ANTHROPIC_API_KEY environment variable', '/home/tor/Downloads/ids2 directory', 'Python/shell/yaml files in project'],
        outputs=['dependency_map_ai.html interactive visualization', 'analysis_cache.json cache file', 'Console logs with progress monitoring']
    ),
    StepConfig(
        name="h.py",
        script="h.py",
        state=State.H_PY,
        description="Generates an interactive HTML dependency graph visualization for Python/shell scripts in the project",
        timeout=120,
        can_fail=True,
        on_failure="abort",
        inputs=['project directory structure', 'Python/shell/bash files', 'plotly'],
        outputs=['graph_interactif.html interactive visualization file']
    ),
    StepConfig(
        name="generate_graph.py",
        script="generate_graph.py",
        state=State.GENERATE_GRAPH_PY,
        description="Generates a visual dependency graph of scripts in a project using Graphviz, showing relationships be",
        timeout=300,
        can_fail=True,
        on_failure="abort",
        inputs=['project_directory_files', 'graphviz_library', 'script_files_with_extensions'],
        outputs=['graphe_complet.png', 'console_output', 'dependency_graph_visualization']
    ),
    StepConfig(
        name="yu.py",
        script="yu.py",
        state=State.YU_PY,
        description="A dependency analyzer tool that scans project files to extract and visualize dependencies between di",
        timeout=300,
        can_fail=True,
        on_failure="abort",
        inputs=['project_directory_structure', 'python_files', 'shell_scripts'],
        outputs=['dependency_map.html', 'console_analysis_output', 'networkx_graph_object']
    ),
    StepConfig(
        name="i.py",
        script="i.py",
        state=State.I_PY,
        description="Generates a dependency graph visualization of project scripts using Graphviz. Analyzes .sh, .py, and",
        timeout=120,
        can_fail=True,
        on_failure="abort",
        inputs=['project directory structure', 'script files (.sh, .py, .bash)', 'graphviz library'],
        outputs=['mon_architecture_ids2.png', 'dependency graph visualization', 'console analysis summary']
    ),
    StepConfig(
        name="aa.py",
        script="aa.py",
        state=State.AA_PY,
        description="Analyzes code dependencies in a project directory using Claude AI and generates an interactive HTML ",
        timeout=300,
        can_fail=True,
        on_failure="abort",
        inputs=['/home/tor/Downloads/ids2 directory', 'Anthropic API key', 'files with extensions: .py, .sh, .yml, .yaml, .service, Dockerfile'],
        outputs=['ai_dependency_map.html', 'console output with analysis progress', 'NetworkX graph structure']
    ),
]

# =============================================================================
# EXECUTOR
# =============================================================================

class UnifiedExecutor:
    def __init__(self, project_dir: str = "."):
        self.project_dir = Path(project_dir).resolve()
        self.current_state = State.START
        self.execution_log: List[dict] = []
        self.start_time = time.time()
        
    def _run_script(self, step: StepConfig) -> bool:
        """ExÃ©cute un script avec gestion des erreurs et timeout."""
        script_path = self.project_dir / step.script
        
        if not script_path.exists():
            log.warning(f"Script non trouvÃ©: {step.script}")
            return step.on_failure == "skip"
        
        log.info(f"â–¶ ExÃ©cution: {step.script}")
        log.info(f"  Description: {step.description}")
        
        # PrÃ©parer la commande
        if step.script.endswith('.py'):
            cmd = [sys.executable, str(script_path)]
        elif step.script.endswith(('.sh', '.bash')):
            cmd = ['bash', str(script_path)]
        else:
            cmd = [str(script_path)]
        
        # ExÃ©cuter avec timeout
        retries = 0
        while retries <= step.max_retries:
            try:
                start = time.time()
                result = subprocess.run(
                    cmd,
                    cwd=str(self.project_dir),
                    timeout=step.timeout,
                    capture_output=True,
                    text=True,
                    env={**os.environ, 'PYTHONPATH': str(self.project_dir)}
                )
                duration = time.time() - start
                
                if result.returncode == 0:
                    log.info(f"  âœ… SuccÃ¨s en {duration:.1f}s")
                    self.execution_log.append({
                        'step': step.name,
                        'status': 'success',
                        'duration': duration
                    })
                    return True
                else:
                    log.error(f"  âŒ Ã‰chec (code {result.returncode})")
                    if result.stderr:
                        log.error(f"  Erreur: {result.stderr[:500]}")
                    
                    if step.on_failure == "retry" and retries < step.max_retries:
                        retries += 1
                        log.info(f"  ðŸ”„ Retry {retries}/{step.max_retries}...")
                        time.sleep(2)
                        continue
                    elif step.on_failure == "skip":
                        log.warning(f"  â­ï¸ Skip (non critique)")
                        return True
                    else:
                        return False
                        
            except subprocess.TimeoutExpired:
                log.error(f"  â° Timeout aprÃ¨s {step.timeout}s")
                if step.on_failure == "skip":
                    return True
                return False
            except Exception as e:
                log.error(f"  ðŸ’¥ Exception: {e}")
                return False
        
        return False
    
    def run(self, start_from: Optional[str] = None, dry_run: bool = False) -> bool:
        """ExÃ©cute tous les steps dans l'ordre."""
        log.info("=" * 60)
        log.info("UNIFIED EXECUTION - START")
        log.info(f"Project: {self.project_dir}")
        log.info(f"Steps: {len(EXECUTION_STEPS)}")
        log.info("=" * 60)
        
        started = start_from is None
        
        for i, step in enumerate(EXECUTION_STEPS, 1):
            if not started:
                if step.script == start_from:
                    started = True
                else:
                    continue
            
            log.info(f"\n[{i}/{len(EXECUTION_STEPS)}] {step.state.name}")
            
            if dry_run:
                log.info(f"  [DRY-RUN] Would execute: {step.script}")
                continue
            
            self.current_state = step.state
            
            if not self._run_script(step):
                log.error(f"\nðŸ’€ EXECUTION FAILED at step: {step.name}")
                self.current_state = State.ERROR
                self._print_summary()
                return False
        
        self.current_state = State.SUCCESS
        log.info("\n" + "=" * 60)
        log.info("âœ¨ ALL STEPS COMPLETED SUCCESSFULLY")
        log.info("=" * 60)
        
        self._print_summary()
        return True
    
    def _print_summary(self):
        """Affiche le rÃ©sumÃ© d'exÃ©cution."""
        duration = time.time() - self.start_time
        log.info(f"\nðŸ“Š SUMMARY")
        log.info(f"  Total duration: {duration:.1f}s")
        log.info(f"  Final state: {self.current_state.name}")
        log.info(f"  Steps executed: {len(self.execution_log)}")
        
        success = sum(1 for l in self.execution_log if l['status'] == 'success')
        log.info(f"  Successful: {success}/{len(self.execution_log)}")

# =============================================================================
# MAIN
# =============================================================================

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="Unified Execution Script")
    parser.add_argument('--dry-run', action='store_true', help='Simulation sans exÃ©cution')
    parser.add_argument('--start-from', type=str, help='DÃ©marrer Ã  partir de ce script')
    parser.add_argument('--list', action='store_true', help='Lister les Ã©tapes')
    parser.add_argument('-d', '--dir', default='.', help='RÃ©pertoire du projet')
    
    args = parser.parse_args()
    
    if args.list:
        print("\nðŸ“‹ Ã‰TAPES D'EXÃ‰CUTION:\n")
        for i, step in enumerate(EXECUTION_STEPS, 1):
            print(f"  {i:2d}. [{step.state.name:15s}] {step.script}")
            print(f"      {step.description}")
        return
    
    executor = UnifiedExecutor(args.dir)
    success = executor.run(start_from=args.start_from, dry_run=args.dry_run)
    
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()
