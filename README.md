# Architecture du pipeline SOC IDS

Ce document d√©crit l‚Äôarchitecture cible du pipeline SOC pour un IDS Suricata d√©ploy√© sur **Raspberry Pi 5 (8 GB RAM)**, avec ingestion vers **AWS OpenSearch**, orchestration Python, parall√©lisme contr√¥l√© et d√©ploiement Docker.

---

## 0) Contexte mat√©riel & contraintes

### Raspberry Pi cible

| √âl√©ment          | Valeur                       |
| ---------------- | ---------------------------- |
| Mod√®le           | Raspberry Pi 5               |
| RAM              | 8 GB                         |
| CPU              | 4 √ó Cortex-A76               |
| OS               | Debian GNU/Linux 13 (Trixie) |
| IP fixe          | **192.168.178.66**           |
| Interface r√©seau | **eth0 uniquement**          |
| Swap             | 2 GB                         |
| Stockage         | microSD 119 GB               |

### Contraintes cl√©s

* **CPU total utilis√© ‚â§ 70 %**
* **RAM totale utilis√©e ‚â§ 70 %**
* Tol√©rance aux pics de trafic (burst IDS)
* Aucun blocage r√©seau ou CPU lors des tests AWS
* Pipeline r√©silient (buffer + backpressure)

---

## 1) Biblioth√®ques n√©cessaires

### Python (`requirements.txt`)

| Biblioth√®que      | R√¥le                                    |
| ----------------- | --------------------------------------- |
| boto3             | SDK AWS (cr√©ation / gestion OpenSearch) |
| opensearch-py     | Client OpenSearch (bulk, health checks) |
| uvloop            | Boucle asyncio ultra-performante        |
| asyncio           | Parall√©lisme I/O                        |
| orjson            | S√©rialisation JSON rapide               |
| msgpack-python    | Format binaire rapide (interne)         |
| aioredis          | Buffer Redis asynchrone                 |
| PyYAML            | Parsing `config.yaml`                   |
| watchdog          | Suivi temps r√©el de `eve.json`          |
| requests          | HTTP simple                             |
| prometheus-client | Export m√©triques                        |
| GitPython         | Commit / push sur branche `dev`         |
| pytest            | Tests                                   |

---

## 2) Strat√©gie globale

Le projet repose sur une **strat√©gie ‚Äúpipeline orient√© flux‚Äù**, d√©coupl√©e, asynchrone et r√©siliente.

### Principes cl√©s

* **D√©couplage** : Suricata ‚â† Vector ‚â† OpenSearch
* **Backpressure** : Redis absorbe les pics
* **Async first** : aucun appel r√©seau bloquant
* **Configuration unique** : `config.yaml`
* **Automatisation totale** : z√©ro configuration manuelle
* **Observabilit√© native** : m√©triques partout

---

## 3) Qu‚Äôest-ce que l‚ÄôAWS SDK (boto3) ?

`boto3` est le **SDK officiel AWS pour Python**.

Il permet :

* Authentification via **SigV4**
* Appels API s√©curis√©s
* Cr√©ation / description de ressources AWS
* Polling d‚Äô√©tat non bloquant

### Utilisation dans ce projet

* Cr√©ation ou r√©cup√©ration du **OpenSearch Domain**
* Attente de l‚Äô√©tat `ACTIVE`
* R√©cup√©ration de l‚Äôendpoint
* Application d‚Äôindex templates
* Tests de connectivit√©

---

## 4) Qu‚Äôest-ce que le pipeline SOC ?

Un pipeline SOC est une **cha√Æne continue de traitement de logs s√©curit√©**.

### Cha√Æne logique

1. Capture r√©seau (Suricata)
2. √âcriture JSON (`eve.json`)
3. Parsing / mapping ECS (Vector)
4. Bufferisation (Redis)
5. Ingestion bulk (OpenSearch)
6. Visualisation / alertes
7. Monitoring syst√®me & pipeline

### Sch√©ma simplifi√©

```
Suricata ‚Üí Vector ‚Üí Redis ‚Üí OpenSearch
              ‚Üì
         Prometheus ‚Üí Grafana
```

---

## 5) Structures de donn√©es

### 5.1 Suricata JSON (eve.json)

```json
{
  "timestamp": "2026-02-01T02:10:00.123Z",
  "event_type": "alert",
  "src_ip": "192.168.178.5",
  "dest_ip": "10.0.0.10",
  "alert": {
    "signature": "ET SCAN ...",
    "severity": 2
  }
}
```

---

### 5.2 ECS (apr√®s Vector)

```json
{
  "@timestamp": "2026-02-01T02:10:00.123Z",
  "event": {
    "kind": "alert",
    "category": "network"
  },
  "source": {
    "ip": "192.168.178.5"
  },
  "destination": {
    "ip": "10.0.0.10"
  },
  "suricata": {
    "signature": "ET SCAN ...",
    "severity": 2
  }
}
```

---

### 5.3 Bulk OpenSearch (NDJSON)

```
{ "index": { "_index": "suricata-2026.02.01" } }
{ "doc ECS" }
```

---

## 6) Phases du syst√®me

### Phase A ‚Äî Initialisation Raspberry Pi

* D√©sactiver toutes les interfaces sauf `eth0`
* Configurer firewall minimal
* Cr√©er RAM disk pour logs
* Installer Docker & Python

---

### Phase B ‚Äî Provisioning AWS

* Charger `config.yaml`
* V√©rifier credentials
* Cr√©er ou d√©tecter domaine
* Attendre `ACTIVE`
* Sauvegarder endpoint

---

### Phase C ‚Äî Tests r√©seau (asynchrones)

Ex√©cut√©s **en parall√®le** :

* DNS
* TLS
* Bulk

---

### Phase D ‚Äî G√©n√©ration de configurations

* `suricata.yaml`
* `vector.toml`
* `docker-compose.yml`
* `prometheus.yml`
* Dashboards Grafana

---

### Phase E ‚Äî D√©ploiement Docker

* Redis
* Vector
* Prometheus
* Grafana

---

### Phase F ‚Äî Ingestion & monitoring

* Tail `eve.json`
* Vector ‚Üí Redis ‚Üí OpenSearch
* Export m√©triques
* Alerting

---

### Phase G ‚Äî Git (branche dev)

* V√©rification branche `dev`
* Commit automatique
* Push sur `dev`

---

## 7) Conteneurs Docker

| Conteneur     | R√¥le                                |
| ------------- | ----------------------------------- |
| Suricata      | Capture r√©seau + d√©tection IDS      |
| Redis         | Buffer backpressure                 |
| Vector        | Parsing + ingestion                 |
| Prometheus    | Collecte m√©triques                  |
| Grafana       | Dashboards                          |
| cAdvisor      | Surveillance des conteneurs Docker  |
| Node Exporter | Surveillance des ressources h√¥tes   |

---

## 8) Parall√©lisme & multithreading

### 8.1 Parall√©lisme Python (I/O)

Utilis√© pour :

* DNS
* TLS
* Tests bulk
* Monitoring

```python
await asyncio.gather(
  test_dns(),
  test_tls(),
  test_bulk()
)
```

### 8.2 Vector (natif)

Vector est √©crit en **Rust**, multi-thread nativement :

* Lecture fichiers
* Parsing ECS
* Batching
* Retry/backoff

---

## 9) Gestion CPU & RAM (< 70 %)

### R√©partition CPU

| Composant     | CPU     |
| ------------- | ------- |
| Suricata      | 3 c≈ìurs |
| Vector        | 1 c≈ìur  |
| Redis         | 0.5 c≈ìur |
| Prometheus    | 0.2 c≈ìur |
| Grafana       | 0.2 c≈ìur |
| cAdvisor      | 0.1 c≈ìur |
| Node Exporter | 0.1 c≈ìur |

### R√©partition RAM

| Composant     | RAM max |
| ------------- | ------- |
| Suricata      | ~4 GB   |
| Vector        | ~1 GB   |
| Redis         | ~512 MB |
| Prometheus    | ~256 MB |
| Grafana       | ~256 MB |
| cAdvisor      | ~64 MB  |
| Node Exporter | ~64 MB  |
| Libre         | >1 GB   |

### M√©canismes de contr√¥le

* Limites Docker (`mem_limit`, `cpus`)
* Batching Vector
* Chunking async Python
* Garbage collection Python forc√©e
* Rotation logs RAM disk

---

## 10) R√©seau & s√©curit√©

### Interface

* **eth0 uniquement**
* IP : **192.168.178.66**

```bash
ip link set wlan0 down
ip link set usb0 down
```

### Firewall minimal

```bash
iptables -A OUTPUT -o eth0 -p tcp --dport 443 -j ACCEPT
iptables -A OUTPUT -o eth0 -p udp --dport 53 -j ACCEPT
iptables -P OUTPUT DROP
iptables -P INPUT DROP
```

---

## 11) Agent SOC

Le projet inclut un **agent SOC Python** qui :

* Orchestre toutes les phases
* Surveille l‚Äô√©tat du pipeline
* Expose m√©triques Prometheus
* G√®re les retries
* Contr√¥le l‚Äôutilisation CPU/RAM
* Peut √™tre lanc√© comme **service systemd**

üëâ L‚Äôagent est le **cerveau du syst√®me**.

---

## 12) Amazon Q dans VS Code

### Pr√©requis

* Extension **AWS Toolkit / Amazon Q** install√©e
* Profil AWS d√©j√† configur√© : **`moi33`**
* Variables AWS d√©j√† pr√©sentes

### Configuration

Dans VS Code :

1. Ouvrir **AWS Toolkit**
2. S√©lectionner le profil **`moi33`**
3. V√©rifier la r√©gion (`eu-central-1`)

### Utilisation avec ce projet

Amazon Q peut :

* Expliquer le code
* G√©n√©rer des tests
* V√©rifier la config AWS
* Aider √† d√©boguer Vector / Suricata

Aucune configuration suppl√©mentaire requise.

---

## 13) R√©sum√© final

‚úî Architecture robuste
‚úî Async & multithread contr√¥l√©
‚úî Limites CPU/RAM respect√©es
‚úî Observabilit√© compl√®te
‚úî S√©curit√© r√©seau stricte
‚úî D√©ploiement reproductible
‚úî Agent SOC central
‚úî Compatible Amazon Q / VS Code
Parfait ‚Äî j‚Äôai **adapt√© et enrichi ton README** en int√©grant **la Web App de contr√¥le (Control Plane)**, **la visualisation**, **le red√©marrage des services**, **la modification des param√®tres**, tout en restant **coh√©rent avec toute la discussion** (systemd, Docker, agent, Pi 5).

Tu peux **copier-coller tel quel** ce README et remplacer l‚Äôactuel.

---

# Architecture du pipeline SOC IDS

Ce document d√©crit l‚Äôarchitecture cible du pipeline SOC pour un IDS Suricata d√©ploy√© sur **Raspberry Pi 5 (8 GB RAM)**, avec ingestion vers **AWS OpenSearch**, orchestration Python **multi-process**, parall√©lisme contr√¥l√©, **interface Web de pilotage**, et d√©ploiement Docker.

---

## 0) Contexte mat√©riel & contraintes

### Raspberry Pi cible

| √âl√©ment          | Valeur                       |
| ---------------- | ---------------------------- |
| Mod√®le           | Raspberry Pi 5               |
| RAM              | 8 GB                         |
| CPU              | 4 √ó Cortex-A76               |
| OS               | Debian GNU/Linux 13 (Trixie) |
| IP fixe          | **192.168.178.66**           |
| Interface r√©seau | **eth0 uniquement**          |
| Swap             | 2 GB                         |
| Stockage         | microSD 119 GB               |

### Contraintes cl√©s

* **CPU total utilis√© ‚â§ 70 %**
* **RAM totale utilis√©e ‚â§ 70 %**
* Tol√©rance aux pics de trafic (burst IDS)
* Aucun appel r√©seau bloquant dans la boucle critique
* Pipeline r√©silient (buffer + backpressure)
* Administration locale via Web UI (LAN uniquement)

---

## 1) Biblioth√®ques n√©cessaires

### Python (`requirements.txt`)

| Biblioth√®que      | R√¥le                                    |
| ----------------- | --------------------------------------- |
| boto3             | SDK AWS (cr√©ation / gestion OpenSearch) |
| opensearch-py     | Client OpenSearch (bulk, health checks) |
| uvloop            | Boucle asyncio ultra-performante        |
| asyncio           | Parall√©lisme I/O                        |
| orjson            | S√©rialisation JSON rapide               |
| msgpack-python    | Format binaire interne                  |
| aioredis          | Buffer Redis asynchrone                 |
| PyYAML            | Parsing `config.yaml`                   |
| watchdog          | Suivi temps r√©el de `eve.json`          |
| requests          | HTTP                                    |
| prometheus-client | Export m√©triques                        |
| psutil            | CPU / RAM                               |
| fastapi           | Web Control Plane                       |
| uvicorn           | Serveur API                             |
| docker            | Pilotage Docker                         |
| GitPython         | Commit / push sur branche `dev`         |
| pytest            | Tests                                   |

---

## 2) Strat√©gie globale

Le projet repose sur une **strat√©gie pipeline orient√©e flux**, **pilot√©e par un agent central**, observable et contr√¥lable via **interface Web locale**.

### Principes cl√©s

* **D√©couplage fort** : Suricata ‚â† Vector ‚â† OpenSearch
* **Backpressure** : Redis absorbe les pics
* **Async + multi-process** : s√©paration contr√¥le / ingestion / monitoring
* **Configuration unique** : `config.yaml`
* **Contr√¥le dynamique** : param√®tres ajustables sans reboot
* **Observabilit√© native** : m√©triques + dashboards
* **Administration Web locale** : actions sans SSH

---

## 3) R√¥le de l‚ÄôAWS SDK (boto3)

`boto3` est le **SDK officiel AWS pour Python**.

Utilis√© pour :

* Cr√©er / d√©crire un domaine OpenSearch
* Poller l‚Äô√©tat (`CREATING ‚Üí ACTIVE`)
* R√©cup√©rer l‚Äôendpoint
* Appliquer templates et policies
* Tester la connectivit√© (SigV4)

---

## 4) Pipeline SOC (concept)

Cha√Æne de traitement :

1. Capture r√©seau (port mirroring ‚Üí eth0)
2. D√©tection IDS (Suricata)
3. Logs JSON (`eve.json`)
4. Parsing & mapping ECS (Vector)
5. Buffer Redis (si pression)
6. Ingestion bulk (OpenSearch)
7. Visualisation & alertes
8. Pilotage Web & monitoring

```
Suricata ‚Üí Vector ‚Üí Redis ‚Üí OpenSearch
              ‚Üì
        Prometheus ‚Üí Grafana
              ‚Üì
          FastAPI UI
```

---

## 5) Structures de donn√©es

### 5.1 Suricata JSON (`eve.json`)

```json
{
  "timestamp": "2026-02-01T02:10:00.123Z",
  "event_type": "alert",
  "src_ip": "192.168.178.5",
  "dest_ip": "10.0.0.10",
  "alert": {
    "signature": "ET SCAN ...",
    "severity": 2
  }
}
```

### 5.2 ECS (apr√®s Vector)

```json
{
  "@timestamp": "2026-02-01T02:10:00.123Z",
  "event": { "kind": "alert", "category": "network" },
  "source": { "ip": "192.168.178.5" },
  "destination": { "ip": "10.0.0.10" },
  "suricata": { "signature": "ET SCAN ...", "severity": 2 }
}
```

### 5.3 Bulk OpenSearch (NDJSON)

```
{ "index": { "_index": "suricata-2026.02.01" } }
{ ... ECS document ... }
```

---

## 6) Phases du syst√®me

### Phase A ‚Äî Initialisation Pi

* D√©sactivation interfaces hors `eth0`
* Mode promiscuous
* Firewall minimal
* RAM disk logs
* Installation Docker + Python

### Phase B ‚Äî Provisioning AWS

* Lecture `config.yaml`
* V√©rification credentials
* Cr√©ation ou r√©cup√©ration domaine
* Attente `ACTIVE`
* Sauvegarde endpoint

### Phase C ‚Äî Tests r√©seau (async)

* DNS
* TLS
* Bulk OpenSearch
  ‚Üí **ex√©cut√©s en parall√®le**

### Phase D ‚Äî G√©n√©ration des configurations

* `suricata.yaml`
* `vector.toml`
* `docker-compose.yml`
* `prometheus.yml`
* Dashboards Grafana

### Phase E ‚Äî D√©ploiement Docker

* Redis
* Vector
* Prometheus
* Grafana
* FastAPI Control Plane

### Phase F ‚Äî Ingestion & Monitoring

* Tail `eve.json`
* Vector ‚Üí Redis ‚Üí OpenSearch
* M√©triques Prometheus
* Dashboards Grafana

### Phase G ‚Äî Pilotage & Git

* Interface Web pour actions
* Commit auto sur branche `dev`
* Push contr√¥l√©

---

## 7) Conteneurs Docker

| Conteneur     | R√¥le                    |
| ------------- | ----------------------- |
| Redis         | Buffer / backpressure   |
| Vector        | Parsing ECS + ingestion |
| Prometheus    | Collecte m√©triques      |
| Grafana       | Visualisation           |
| FastAPI       | Web Control Plane       |
| cAdvisor      | M√©triques Docker        |
| Node Exporter | M√©triques h√¥te          |

‚ö†Ô∏è **Suricata n‚Äôest PAS dockeris√©** (capture r√©seau).

---

## 8) Parall√©lisme & multi-process

### Python (agent SOC)

* **Process Supervisor**
* **Process contr√¥le ressources**
* **Process tests r√©seau (async)**
* **Process m√©triques**
* (optionnel) **Process v√©rification ingestion**

### Async I/O

```python
await asyncio.gather(
  test_dns(),
  test_tls(),
  test_bulk()
)
```

### Vector

* Multithread natif (Rust)
* Batching, retry, backoff int√©gr√©s

---

## 9) Gestion CPU & RAM (< 70 %)

### R√©partition CPU

| Composant | CPU     |
| --------- | ------- |
| Suricata  | 3 c≈ìurs |
| Vector    | 1 c≈ìur  |
| Autres    | limit√©  |

### R√©partition RAM

| Composant    | RAM max |
| ------------ | ------- |
| Suricata     | ~4 GB   |
| Vector       | ~1 GB   |
| Redis        | ~512 MB |
| Stack Docker | ~1 GB   |
| Libre        | >1 GB   |

### M√©canismes

* `CPUQuota` / `MemoryMax` systemd
* Limites Docker (`cpus`, `mem_limit`)
* Throttling dynamique agent
* Chunking async
* GC Python sous pression
* Rotation logs RAM disk

---

## 10) R√©seau & s√©curit√©

### Interface

* **eth0 uniquement**
* IP : **192.168.178.66**

```bash
ip link set wlan0 down
ip link set usb0 down
```

### Firewall minimal

```bash
iptables -A OUTPUT -o eth0 -p tcp --dport 443 -j ACCEPT
iptables -A OUTPUT -o eth0 -p udp --dport 53 -j ACCEPT
iptables -P OUTPUT DROP
iptables -P INPUT DROP
```

---

## 11) Agent SOC (cerveau)

L‚Äôagent SOC Python :

* Orchestre toutes les phases
* Supervise les services
* Surveille CPU / RAM
* Applique throttling
* Expose m√©triques Prometheus
* Pilote Docker et systemd
* Sert de backend √† la Web UI

---

## 12) Web Control Plane (UI)

### Composants

* **FastAPI** (backend API)
* **Swagger UI** (`/docs`)
* **Grafana** (graphiques)
* **Prometheus** (donn√©es)

### Fonctions Web

* Visualiser l‚Äô√©tat du pipeline
* Voir CPU / RAM / d√©bit
* Modifier `config.yaml`
* Ajuster batch Vector
* Red√©marrer :

  * Suricata
  * Agent
  * Docker stack
* Voir l‚Äô√©tat systemd / Docker

Acc√®s local :

```
http://192.168.178.66:8000/docs
http://192.168.178.66:3000
```

---

## 13) Amazon Q dans VS Code

### Pr√©requis

* Extension AWS Toolkit / Amazon Q
* Profil AWS : **`moi33`**
* R√©gion : `eu-central-1`

### Usage

* Analyse du code
* Debug config AWS
* G√©n√©ration de tests
* Aide Vector / Suricata

---

## 14) R√©sum√© final

‚úî IDS passif haute performance
‚úî Pipeline r√©silient & observable
‚úî Multi-process & async ma√Ætris√©s
‚úî Limites CPU/RAM garanties
‚úî Pilotage Web local
‚úî D√©ploiement reproductible
‚úî Compatible Amazon Q / VS Code
‚úî Adapt√© production 24/7

---

Si tu veux la suite, je peux maintenant :

* g√©n√©rer **l‚ÄôAPI FastAPI compl√®te**
* g√©n√©rer **les dashboards Grafana**
* int√©grer **le contr√¥le Web directement dans l‚Äôagent**
* fournir **les r√®gles RBAC**

Dis-moi üöÄ
